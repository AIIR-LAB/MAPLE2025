<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>MAPLE2025 @ ICMLA 2025</title>
  <link rel="stylesheet" href="styles.css" />
</head>

<body>
  <!-- Navbar -->
  <nav id="navbar">
    <ul>
      <li><a href="#home">Home</a></li>
      <li><a href="#intro">Introduction</a></li>
      <li><a href="#tracks">Scope</a></li>
      <li><a href="#challenge-dates">Submission Guidelines </a></li>
      <li><a href="#papers">Paper Publication</a></li>
      <li><a href="#paper-dates">Important Dates</a></li>
      <li><a href="#speakers">Program Committee</a></li>
      <li><a href="#organizers">Organizers</a></li>
      <li><a href="#contact">Contact</a></li>
    </ul>
  </nav>

  <!-- Hero -->
  <header class="hero">
    <h1>Multi-modal Machine Learning in Practice: Algorithms and Applications (MAPLE2025)</h1>
    <p>Special Session in conjunction with ICMLA 2025</p>
    <p><strong>3-5 December 2025</strong></p>
    <p><strong>Boca Raton Marriott at Boca Center, Florida</strong></p>
  </header>

  <main>
    <!-- Introduction -->
    <section id="intro">
      <h2>Introduction</h2>
      <p>This special session aims to highlight cutting-edge research in the development and practical deployment of
        multimodal machine learning algorithms that integrate and process heterogeneous data types—such as text, image,
        audio, video, and sensor signals—to address complex, real-world challenges. By leveraging the complementary
        strengths of multiple modalities, these systems enable more robust, context-aware, and intelligent solutions
        across a wide range of domains, including healthcare, cybersecurity, robotics, smart environments,
        transportation, surveillance and so on.
        The session invites contributions where algorithmic innovations in multi-modal AI systems are developed in the
        context of real-world applications, leading to tangible improvements in performance, scalability, and
        interpretability. We particularly welcome work demonstrating multi-modal AI in domains such as healthcare,
        cybersecurity, robotics, smart homes, transportation, and surveillance. We also encourage submissions focusing
        on educational tools, mobile and web-based AI systems, multi-modal chatbot development, and cross-modal
        retrieval tasks.</p>
    </section>
    <section id="scope">
      <h2>Scopes</h2>
      <h4>This workshop will cover but not limit to the following topics:</h4>
      <ul>
        <li>Vision-language and multi-modal foundation models</li>
        <li>Generative models for multi-modal synthesis</li>
        <li>Multi-modal representation alignment and fusion techniques</li>
        <li>Transfer learning and fine-tuning strategies in multi-modal deep learning</li>
        <li>Cross-modal retrieval and matching (e.g., image-to-text, audio-to-video)</li>
        <li>Domain adaptation and self-supervised learning for multi-modal data</li>
        <li>Explainable, interpretable, and trustworthy multi-modal ML systems</li>
        <li>Applications in cybersecurity, medical imaging, transportation, robotics, and smart environments</li>
        <li>Mobile, web, and edge deployment of multi-modal systems</li>
        <li>Real-time architectures and lightweight multi-modal models for deployment</li>
        <li>Benchmark datasets, framework, and reproducibility in multi-modal ML </li>
      </ul>
    </section>

    <section id="submission">
      <h2>Submission Guidelines and Instructions</h2>
      <ul>
        <li>Papers submitted for reviewing should conform to IEEE specifications. Manuscript templates can be downloaded
          from <a href="IEEE website">https://www.ieee.org/conferences/publishing/templates.html</a>
        </li>
        <li>The maximum length of papers is 8 (eight) pages.</li>
        <li>All the papers will go through double-blind peer review process.</li>
        <li>Authors’ names and affiliations should not appear in the submitted papers.</li>
        <li>Authors’ prior work should be cited in the third person.</li>
        <li>Authors should take care and avoid revealing their identities and/or institutions in the paper’s text,
          figures, links, etc.</li>
        <li>Any papers that do not adhere to the double-blind peer review policy will be rejected without peer review.
        </li>
      </ul>


    </section>
    <section id="publication">
      <h2> Paper Publication </h2>
      <p>Accepted papers will be published in the ICMLA 2025 conference proceedings by <a href="IEEE">https://www.ieee.org/publications-research</a>. A selected number of
        accepted papers will be invited for possible inclusion, in an expanded and revised form, in some Special Issues
        of Journals. </p>
    </section>


    <!-- Schedule -->
    <!-- <section id="schedule">
      <h2>Important Dates</h2>
      <p>The workshop will be held on December 5, 2025, at Boca Raton Marriott at Boca Center, Florida.</p>
      <table>
        <tr><th>Event</th><th>Time</th></tr>
        <tr><td>Chairs' opening remarks</td><td>13:30 PM</td></tr>
      </table>
      <p><em>*All times are in local conference time.</em></p>
    </section> -->


    <!-- Call for Paper -->
    <!-- <section id="papers">
      <h2>Call for Papers</h2>
      <p>MAPLE 2025 will be using CMT to manage submissions. We are looking forward to your work and engaging discussions at the workshop!</p>
      <p>We invite authors to submit unpublished papers (8-page CVPR format) to our workshop, to be presented at a poster session upon acceptance. All submissions will go through a double-blind review process. All contributions must be submitted (along with supplementary materials, if any) through the paper submission portal.</p>
      <p>Accepted papers will be published in the official CVPR Workshops proceedings and the Computer Vision Foundation (CVF) Open Access archive.</p>
    </section> -->

    <!-- Paper Timeline -->
    <section id="paper-dates">
      <h2>Important Dates</h2>
      <table>
        <tr>
          <th>Event</th>
          <th>Date</th>
        </tr>
        <tr>
          <td>Submission deadline</td>
          <td>August 20, 2025</td>
        </tr>
        <tr>
          <td>Notification of Acceptance</td>
          <td> September 10, 2025</td>
        </tr>
        <tr>
          <td>Camera Ready Papers</td>
          <td>September 20, 2025</td>
        </tr>
        <tr>
          <td>Pre-Registration</td>
          <td>September 20, 2025</td>
        </tr>
      </table>
    </section>



    <!-- Organizers -->
    <section id="organizers">
      <h2>Organizers</h2>
      <div class="organizer-grid">
        <div class="organizer">
          <h2>Session Chairs</h2>
          <h3>Dr. Md Belayat Hossain</h3>
          <p>Southern Illinois University Carbondale</p>
        </div>
        <div class="organizer">
          <h3>Dr. Abdur Rahman Bin Shahid</h3>
          <p>Southern Illinois University Carbondale</p>
        </div>
        <div class="organizer">
          <h2>Publicity Chairs</h2>
          <h3>Golam Jilani</h3>
          <p>Southern Illinois University Carbondale</p>
        </div>
        <div class="organizer">
          <h3>Mohd Farhan Israk Soumik</h3>
          <p>Southern Illinois University Carbondale</p>
        </div>
      </div>
    </section>


    <!-- Speakers -->
    <section id="speakers">
      <h2>Technical Program Committee Members</h2>
      <div class="speaker-grid">
        <div class="speaker">
          <h3>Dr. Kento Morita</h3>
          <p>Mie University</p>
        </div>
        <div class="speaker">
          <h3></h3>
          <p></p>
        </div>
        <div class="speaker">
          <h3></h3>
          <p></p>
        </div>
      </div>
    </section>

    <!-- Contact -->
    <section id="contact">
      <h2>Contact</h2>
      <p>Feel free to contact us:</p>
      <p> Dr. Md Belayat Hossain (mdbelayat.hossain@siu.edu) <br /> Dr. Abdur Rahman Bin Shahid
        (abdurrahmanbin.shahid@siu.edu) </p>
    </section>
  </main>

  <footer>
    <p>© Copyright <strong>MAPLE</strong>. All Rights Reserved</p>
  </footer>

  <!-- Optional: smooth scroll -->
  <script>
    document.querySelectorAll('#navbar a').forEach(link => {
      link.addEventListener('click', e => {
        e.preventDefault();
        document.querySelector(link.getAttribute('href')).scrollIntoView({ behavior: 'smooth' });
      });
    });
  </script>
</body>

</html>